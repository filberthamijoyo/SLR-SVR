{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3PAEPRDRLA3"
      },
      "source": [
        "# Support Vector Regression (SVR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCUAVIjRdzZ"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "56oRF-QfSDzC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXVXoFWtSF4_"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xfoa8OSORfHQ"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_excel('Classification iris(2).xlsx')\n",
        "# X = dataset.iloc[:, :-1].values\n",
        "# y = dataset['class'].values\n",
        "# print(dataset.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d33XS1chBJCv"
      },
      "source": [
        "## 2.2.1 Spliting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAWJV6gpiTYM",
        "outputId": "803ade3b-27c9-426a-9850-d5636ab6b4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2.2.1 Split training set and test set:\n",
            "Training set: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135]\n",
            "Test set: [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]\n"
          ]
        }
      ],
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0) cant be used since the split should be per class and trainsplit has no such functionality\n",
        "#the split also must contain the original order of the data\n",
        "#thus we should do it manually\n",
        "training_id = []\n",
        "test_id = []\n",
        "train_ratio = 0.7\n",
        "test_ratio = 0.3\n",
        "classes = dataset['class'].unique()\n",
        "for cls in classes:\n",
        "    cls_dataset = dataset[dataset['class'] == cls]\n",
        "\n",
        "    num_train = int(train_ratio * len(cls_dataset))  #35\n",
        "    num_test = len(cls_dataset) - num_train #15\n",
        "\n",
        "    cls_id = cls_dataset['instance_id'].tolist()\n",
        "\n",
        "    training_id.extend(cls_id[:num_train])\n",
        "    test_id.extend(cls_id[num_train:])\n",
        "\n",
        "#     print(f\"Class {cls}:\")\n",
        "#     print(f\"Training IDs: {cls_id[:num_train]}\")\n",
        "#     print(f\"Test IDs: {cls_id[num_train:]}\")\n",
        "\n",
        "#make sure its still maintains the original order of the data\n",
        "training_id_sorted = sorted(training_id)\n",
        "test_id_sorted = sorted(test_id)\n",
        "\n",
        "print(\"Q2.2.1 Split training set and test set:\")\n",
        "print(f\"Training set: {training_id_sorted}\")\n",
        "print(f\"Test set: {test_id_sorted}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8FeLHYS-nI"
      },
      "source": [
        "## Feature Scaling and Lable Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PGeAlD1HTDI1"
      },
      "outputs": [],
      "source": [
        "#In Support Vector Machines (SVM), feature scaling or normalization are not strictly required, but are highly recommended,\n",
        "#as it can significantly improve model performance and convergence speed.\n",
        "#SVM tries to find the optimal hyperplane that separates the data points of different classes with the maximum margin.\n",
        "#google reference\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = dataset.loc[dataset['instance_id'].isin(training_id_sorted), ['sepal length', 'sepal width', 'petal length', 'petal width']].values\n",
        "y_train = dataset.loc[dataset['instance_id'].isin(training_id_sorted), 'class'].values\n",
        "\n",
        "X_test = dataset.loc[dataset['instance_id'].isin(test_id_sorted), ['sepal length', 'sepal width', 'petal length', 'petal width']].values\n",
        "y_test = dataset.loc[dataset['instance_id'].isin(test_id_sorted), 'class'].values\n",
        "\n",
        "X_train_scaled = sc.fit_transform(X_train)\n",
        "X_test_scaled = sc.transform(X_test)\n",
        "\n",
        "# test\n",
        "# print(\"Training set mean (should be ~0):\", np.round(np.mean(X_train_scaled, axis=0), decimals=6))\n",
        "# print(\"Training set std (should be ~1):\", np.round(np.std(X_train_scaled, axis=0), decimals=6))\n",
        "# print(\"Test set mean:\", np.mean(X_test_scaled, axis=0))\n",
        "# print(\"Test set std:\", np.std(X_test_scaled, axis=0))\n",
        "\n",
        "encode = LabelEncoder()\n",
        "y_train_encoded = encode.fit_transform(y_train)\n",
        "y_test_encoded = encode.transform(y_test)\n",
        "class_names = encode.classes_\n",
        "\n",
        "# test\n",
        "# for idx, cls in enumerate(class_names):\n",
        "#     print(f\"{cls}: {idx}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiU6D2QFRjxY"
      },
      "source": [
        "## 2.2.2 Calculation using Standard SVM Model (Linear Kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6R4rt_GRz15",
        "outputId": "2f04732e-2ee9-42b5-e580-e453d367ff67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Q2.2.2 Calculation using Standard SVM Model:\n",
            "total training error: 0.05714285714285714, total testing error: 0.08888888888888889\n",
            " \n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: [-0.22149841131541403, 0.5197614640017161, -0.6204881374367106, -0.7018619843079239], b: -0.860042567927232\n",
            "support vector indices: [58, 65, 24, 26]\n",
            " \n",
            "class Iris-versicolor:\n",
            "training error: 0.04761904761904762, testing error: 0.06666666666666667\n",
            "w: [1.2403741375019308, -1.5570912008406594, -1.2096160736109596, -0.13571915771171916], b: -0.7952621398225709\n",
            "support vector indices: [2, 4, 9, 10, 13, 14, 26, 31, 32, 35, 102, 103, 104, 106, 107, 108, 109, 112, 113, 114, 117, 119, 120, 123, 124, 126, 127, 129, 130, 131, 133, 134, 135, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
            " \n",
            "class Iris-virginica:\n",
            "training error: 0.009523809523809525, testing error: 0.0\n",
            "w: [-0.887004583972157, -2.6477127808175283, 9.592181824380532, 10.405861852283124], b: -14.043043467030827\n",
            "support vector indices: [71, 73, 78, 84, 127, 128, 134, 135]\n",
            " \n",
            "Linear separable classes: ['Iris-setosa']\n"
          ]
        }
      ],
      "source": [
        "total_train_errors = 0\n",
        "total_test_errors = 0\n",
        "class_results = {}\n",
        "linearly_separable_classes = []\n",
        "\n",
        "#(hard margin)\n",
        "svm_model = SVC(kernel='linear', C=1e5, random_state=0)\n",
        "\n",
        "# OvR or OvA\n",
        "ovr = OneVsRestClassifier(svm_model)\n",
        "ovr.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "y_train_pred = ovr.predict(X_train_scaled)\n",
        "y_test_pred = ovr.predict(X_test_scaled)\n",
        "\n",
        "total_train_errors = np.sum(y_train_pred != y_train_encoded) / len(y_train_encoded)\n",
        "total_test_errors = np.sum(y_test_pred != y_test_encoded) / len(y_test_encoded)\n",
        "\n",
        "for idx, cls in enumerate(class_names):\n",
        "    estimator = ovr.estimators_[idx]\n",
        "\n",
        "    w = estimator.coef_[0].tolist()\n",
        "    b = estimator.intercept_[0]\n",
        "\n",
        "    support_vectors_indices = estimator.support_\n",
        "    support_vectors_instance_ids = [training_id_sorted[i] for i in support_vectors_indices]\n",
        "\n",
        "    y_train_binary = (y_train_encoded == idx).astype(int)\n",
        "    y_test_binary = (y_test_encoded == idx).astype(int)\n",
        "\n",
        "    estimator = ovr.estimators_[idx]\n",
        "\n",
        "    y_train_pred_binary = estimator.predict(X_train_scaled)\n",
        "    y_test_pred_binary = estimator.predict(X_test_scaled)\n",
        "\n",
        "    train_error = np.sum(((y_train_pred != y_train_encoded) & (y_train_encoded == idx))/ len(y_train_binary))\n",
        "    test_error = np.sum(((y_test_pred != y_test_encoded) & (y_test_encoded == idx))/ len(y_test_binary))\n",
        "\n",
        "    positive_class_indices = np.where(y_train_encoded == idx)[0]\n",
        "    negative_class_indices = np.where(y_train_encoded != idx)[0]\n",
        "    _train_pred_binary = (y_train_pred == idx).astype(int)\n",
        "\n",
        "# True Positives: Correctly classified positive samples\n",
        "    tp = np.sum(y_train_pred_binary[positive_class_indices] == 1)\n",
        "\n",
        "# False Negatives: Misclassified positive samples\n",
        "    fn = np.sum(y_train_pred_binary[positive_class_indices] == 0)\n",
        "\n",
        "# True Negatives: Correctly classified negative samples\n",
        "    tn = np.sum(y_train_pred_binary[negative_class_indices] == 0)\n",
        "\n",
        "# False Positives: Misclassified negative samples\n",
        "    fp = np.sum(y_train_pred_binary[negative_class_indices] == 1)\n",
        "\n",
        "    if fn == 0 and fp == 0:\n",
        "      linearly_separable_classes.append(cls)\n",
        "\n",
        "    class_results[cls] = {\n",
        "        'training_error': train_error,\n",
        "        'testing_error': test_error,\n",
        "        'w': w,\n",
        "        'b': b,\n",
        "        'support_vectors': support_vectors_instance_ids\n",
        "    }\n",
        "\n",
        "print(\"\\nQ2.2.2 Calculation using Standard SVM Model, my name is filbert hamijoyo:\")\n",
        "\n",
        "print(f\"total training error: {total_train_errors}, total testing error: {total_test_errors}\")\n",
        "print(\" \")\n",
        "\n",
        "for cls in class_names:\n",
        "    result = class_results[cls]\n",
        "    print(f\"class {cls}:\")\n",
        "    print(f\"training error: {result['training_error']}, testing error: {result['testing_error']}\")\n",
        "    print(f\"w: {result['w']}, b: {result['b']}\")\n",
        "    print(f\"support vector indices: {result['support_vectors']}\")\n",
        "    print(\" \")\n",
        "\n",
        "##google reference\n",
        "#When the data is not linearly separable, a linear SVM will still attempt to find the best possible linear hyperplane that separates the classes, but it may not be able to achieve a perfect separation.\n",
        "print(f\"Linear separable classes: {linearly_separable_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deDnDr8UR5vq"
      },
      "source": [
        "## 2.2.3 Calculation using SVM with Slack Variables (Linear Kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib89-Fq8R8v-",
        "outputId": "95ecd257-8586-424f-f498-e35d37fd9170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.25 × t, where t = 1,...,4):\n",
            "-------------------------------------------\n",
            "C=0.25,\n",
            "total training error: 0.08571428571428572, total testing error: 0.08888888888888889\n",
            "\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: [-0.2066  0.5757 -0.566  -0.595 ], b: -0.7129\n",
            "support vector indices: [58, 65, 80, 9, 24, 26]\n",
            "slack variables: [0.006352642943328601, 0.13320812782976255, 0.0, 0.0001248379583259629, 0.0, 0.0840452868089453]\n",
            "\n",
            "class Iris-versicolor:\n",
            "training error: 0.0761904761904762, testing error: 0.06666666666666667\n",
            "w: [ 0.3367 -0.9205 -0.1189 -0.3382], b: -0.8506\n",
            "support vector indices: [2, 3, 4, 9, 10, 13, 14, 26, 31, 35, 102, 103, 104, 106, 107, 108, 109, 112, 113, 114, 115, 117, 119, 120, 122, 123, 124, 127, 128, 129, 130, 131, 133, 134, 135, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
            "slack variables: [0.4778429972383941, 0.00014149461619816783, 0.14910568019877257, 0.4802708195444034, 0.3142625696430478, 0.48316881613391294, 0.3033220388562581, 0.5045060576033948, 0.22237386183705155, 0.3142625696430478, 0.42833983185735314, 0.19739482751075177, 0.23574216741159926, 0.3506521902440105, 0.6036045389885564, 0.5887883683308051, 1.1911451726559954, 0.6547917304082969, 0.10411093914357672, 0.7541791523074703, 0.0, 0.12008839583012043, 1.088967365875324, 1.7071203693584343, 0.11421875683050886, 0.833679511761723, 0.6867069638482045, 0.4511798893551555, 0.00014144709795360644, 0.3420658359426343, 0.47041788144756613, 0.7989739171994487, 0.29678224940992837, 0.6070463556821654, 0.9436109597439067, 1.8502429117482373, 2.1219783968318833, 1.746562312698373, 0.5378444198930782, 1.2798013408629618, 1.5022489552589753, 2.422731118765931, 0.7974254511573703, 1.3514930606523219, 1.5052205976690822, 1.897391853125622, 0.0, 1.6032128390070746, 1.6845972006632348, 1.7479574932595527, 2.0372072169454887, 1.0976343529873218, 0.17972732718669138, 0.805105446538294, 2.4775600555242425, 1.3091811165297236, 0.7730089555697676, 1.3104290054497094, 1.4114665350184041, 1.5856986004047866, 1.1279391586908882, 1.7214757141823018, 1.6751594859047727, 0.8954913383159604, 0.636199200047428, 0.5842682598786267, 1.1749068187805323, 1.355893873270156, 2.117122752219869]\n",
            "\n",
            "class Iris-virginica:\n",
            "training error: 0.009523809523809525, testing error: 0.0\n",
            "w: [ 0.1078 -0.4612  1.3231  1.5083], b: -2.0673\n",
            "support vector indices: [51, 52, 53, 54, 55, 57, 59, 64, 67, 69, 71, 73, 77, 78, 79, 84, 85, 102, 104, 107, 111, 112, 114, 117, 120, 122, 124, 126, 127, 128, 130, 132, 134, 135]\n",
            "slack variables: [0.02325503202462209, 0.0004529764931029412, 0.46167260218241557, 0.023440508662464055, 0.492526045148717, 0.23622120223325438, 0.0001259253273899752, 0.21205214085850832, 0.10072284731734182, 0.9881048301829618, 0.7642059650782085, 0.9928360302402908, 0.47693579808270936, 1.01525223342572, 0.25323725632286465, 1.1016847153732705, 0.07512797891899115, 0.31810083030756076, 0.28881471652939616, 1.0783629492210998, 0.5332057110515986, 0.09336233387019899, 0.00028942480440541374, 0.43852146596101926, 0.6676053101096198, 0.39103782125119846, 0.6040039914598307, 0.18170404287866582, 0.7921030434889809, 0.9335728764846443, 0.530881471515011, 0.000289372441068636, 1.1631840951438648, 0.8181813319246451]\n",
            "-------------------------------------------\n",
            "C=0.5,\n",
            "total training error: 0.06666666666666667, total testing error: 0.044444444444444446\n",
            "\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: [-0.2215  0.5198 -0.6205 -0.7019], b: -0.86\n",
            "support vector indices: [58, 65, 24, 26]\n",
            "slack variables: [0.0, 0.0006537330018741017, 0.0003220104153144332, 9.62118586322891e-06]\n",
            "\n",
            "class Iris-versicolor:\n",
            "training error: 0.05714285714285715, testing error: 0.022222222222222223\n",
            "w: [ 0.4454 -1.0018 -0.2309 -0.3336], b: -0.8228\n",
            "support vector indices: [2, 3, 4, 9, 10, 13, 14, 26, 31, 35, 102, 103, 104, 106, 107, 108, 109, 112, 113, 114, 117, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 133, 134, 135, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
            "slack variables: [0.5327738680235097, 0.0, 0.14121581544378792, 0.4885997425240969, 0.34443014882031164, 0.5245776659278008, 0.2990478179914533, 0.5598042876222735, 0.23400997604525076, 0.34443014882031164, 0.4318444002466659, 0.2660597883868504, 0.23603037800425275, 0.43994520778456325, 0.5631282894685192, 0.6741789667422663, 1.3019748745707593, 0.723137989185719, 0.15914631532128376, 0.7874245294226954, 0.13455770903413744, 1.2451078320675366, 1.8295317214112767, 0.08721587116661689, 0.9647212539720992, 0.7665862156286205, 0.0, 0.506555645054325, 0.0006138163698210519, 0.37500276039617686, 0.5551056882512858, 0.9282864269481942, 0.3303463286238284, 0.6546442528354502, 0.9692179688801776, 1.7594426251407338, 2.095392645852129, 1.6626848612095548, 0.4363965568786847, 1.175094943755148, 1.495692044020295, 2.4388129696027354, 0.7492543586683234, 1.2530184901832986, 1.5070559584841206, 1.8807444061066816, 1.5748491984305995, 1.652433757517355, 1.6591781615000567, 2.0780356291148303, 1.0371366424556956, 0.00020747517932528936, 0.721498040013064, 2.5323584319134285, 1.2197259728747802, 0.6592664013725602, 1.2654472910450234, 1.3199904365154516, 1.4919417515272249, 0.9977028246479412, 1.6505250557841264, 1.646536049801696, 0.7924335896749288, 0.5413505229055786, 0.4837829839985792, 1.1006272917310715, 1.328481036700184, 2.183740896850952]\n",
            "\n",
            "class Iris-virginica:\n",
            "training error: 0.009523809523809525, testing error: 0.0\n",
            "w: [ 0.0341 -0.6345  1.756   1.8244], b: -2.5081\n",
            "support vector indices: [53, 54, 55, 57, 64, 67, 69, 71, 73, 77, 78, 79, 84, 85, 102, 104, 107, 111, 117, 120, 122, 124, 126, 127, 128, 130, 134, 135]\n",
            "slack variables: [0.3139594709815823, 0.000340503251962776, 0.4214139938459833, 0.058783831923995056, 0.11975917800988767, 0.008023075809602709, 1.1474434499168997, 0.7686547276863274, 1.1260211676186893, 0.3856625988134059, 1.0319262874950312, 0.16360649379358128, 1.275693896459234, 0.0, 0.0, 0.011569727823290687, 0.834859725320634, 0.42403410589176893, 0.24104150524678358, 0.3697718623698978, 0.09925168673055484, 0.42001942670986114, 0.0006083271170362892, 0.6616350852600266, 0.8462900769062038, 0.4066724566292388, 1.0958013184408135, 0.5784809973091036]\n",
            "-------------------------------------------\n",
            "C=0.75,\n",
            "total training error: 0.06666666666666667, total testing error: 0.044444444444444446\n",
            "\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: [-0.2215  0.5198 -0.6205 -0.7019], b: -0.86\n",
            "support vector indices: [58, 65, 24, 26]\n",
            "slack variables: [0.0, 0.0006537330018741017, 0.0003220104153144332, 9.62118586322891e-06]\n",
            "\n",
            "class Iris-versicolor:\n",
            "training error: 0.05714285714285715, testing error: 0.022222222222222223\n",
            "w: [ 0.5153 -1.0113 -0.2977 -0.3483], b: -0.8342\n",
            "support vector indices: [2, 3, 4, 9, 10, 13, 14, 26, 31, 35, 102, 103, 104, 106, 107, 108, 109, 112, 113, 114, 117, 119, 120, 122, 123, 124, 126, 127, 129, 130, 131, 133, 134, 135, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
            "slack variables: [0.5499373768523352, 0.0, 0.12767497283672735, 0.46639731067395973, 0.35774527831730285, 0.5354299724234065, 0.2796489861614009, 0.5777877035797907, 0.23331677741651324, 0.35774527831730285, 0.3580131820769149, 0.259894076560655, 0.18277294822041967, 0.4490868613228052, 0.44523382554424706, 0.6776878703694487, 1.2827848422140473, 0.6915856461912453, 0.1430489956283768, 0.7112429243430745, 0.09952678234161683, 1.2557443764124394, 1.7944075356430367, 0.00019933361511925707, 0.9845854038907128, 0.7436664432621671, 0.0, 0.4769869949512543, 0.32618837776093823, 0.5708706696552686, 0.9476714467568185, 0.27955135471248505, 0.6281013404491046, 0.9135783990850378, 1.719390727495009, 2.099600214657806, 1.6382842075622555, 0.4737521231058378, 1.1663745527213334, 1.5456088760684632, 2.462857837142078, 0.8063603374085103, 1.2341381503555593, 1.5759036630455157, 1.91101705850277, 1.6031443611658598, 1.6791119213797008, 1.6307007875937498, 2.1443914920597864, 1.0557831067373606, 6.835752742284651e-05, 0.7470507415736146, 2.595174572314939, 1.2177959142841526, 0.6720583451754157, 1.2876882438604293, 1.3064858541854243, 1.4696631438626075, 0.9695983479906654, 1.6483120877803774, 1.6776317109417667, 0.7948631607564528, 0.569366047467519, 0.506081974044099, 1.1157630520843522, 1.3797868938229567, 2.2666803470145367]\n",
            "\n",
            "class Iris-virginica:\n",
            "training error: 0.009523809523809525, testing error: 0.0\n",
            "w: [-0.0908 -0.5879  1.9794  1.9729], b: -2.7242\n",
            "support vector indices: [53, 55, 57, 64, 69, 71, 73, 77, 78, 79, 84, 85, 107, 111, 117, 120, 122, 124, 126, 127, 128, 130, 134, 135]\n",
            "slack variables: [0.15153575355253346, 0.25012848268914256, 0.000676906497690144, 0.010630207414454418, 0.9467710941502929, 0.8118874469580772, 0.9911903273942331, 0.17500313647546095, 0.9411860281414364, 0.06419528775665295, 1.250677335825471, 0.0, 0.7723179166924723, 0.3925225108301773, 0.21976781356733932, 0.4783108221115926, 0.0001952574036527821, 0.4747500410221899, 0.00019551832664399527, 0.703803767697651, 0.8406766632643308, 0.49147020250376805, 1.1749534335727398, 0.6058388323119823]\n",
            "-------------------------------------------\n",
            "C=1.0,\n",
            "total training error: 0.06666666666666667, total testing error: 0.044444444444444446\n",
            "\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: [-0.2215  0.5198 -0.6205 -0.7019], b: -0.86\n",
            "support vector indices: [58, 65, 24, 26]\n",
            "slack variables: [0.0, 0.0006537330018741017, 0.0003220104153144332, 9.62118586322891e-06]\n",
            "\n",
            "class Iris-versicolor:\n",
            "training error: 0.05714285714285715, testing error: 0.022222222222222223\n",
            "w: [ 0.5335 -1.0093 -0.3441 -0.3167], b: -0.8324\n",
            "support vector indices: [2, 3, 4, 9, 10, 13, 14, 26, 31, 35, 102, 103, 104, 106, 107, 108, 109, 112, 113, 114, 117, 119, 120, 122, 123, 124, 126, 127, 129, 130, 131, 133, 134, 135, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
            "slack variables: [0.5505681259143156, 0.0, 0.11970447596851852, 0.45578695080586706, 0.35199997385783643, 0.5296604255458844, 0.2708717133399171, 0.5753920684012769, 0.22706764655863665, 0.35199997385783643, 0.352939247869948, 0.2719875473644555, 0.17219855676691764, 0.4538225454154319, 0.42689446684195076, 0.6705375526400843, 1.2738161888021915, 0.6942671881791033, 0.15903886282610136, 0.7099294230757347, 0.09631576172079603, 1.2615131518266254, 1.7769657858903192, 0.0006985839087955137, 0.9837236610646263, 0.7503132019656309, 0.0, 0.484528008226192, 0.33004288145711835, 0.5664922714476581, 0.9516449327997913, 0.28764978226110793, 0.6172928197624019, 0.8803378225632903, 1.7071460607905407, 2.090867100295691, 1.629593993914726, 0.4840905508661759, 1.1599134384149794, 1.5622952079997665, 2.4567606788473717, 0.8237698736073455, 1.233549263172301, 1.584038911071754, 1.9062101670741556, 1.611684788729247, 1.6741729734292528, 1.6176103511538704, 2.1538278513837135, 1.0731385739785915, 0.0002404722870690268, 0.7602107697984861, 2.5922656813221328, 1.212899867048284, 0.6790618550188541, 1.3051757676234996, 1.3024355766849383, 1.4591883280045619, 0.9660947976031637, 1.6384973972606058, 1.6789018304122032, 0.7992859795968053, 0.5825503181104297, 0.5209187903756811, 1.1194479152931083, 1.393279855413176, 2.280429450512596]\n",
            "\n",
            "class Iris-virginica:\n",
            "training error: 0.009523809523809525, testing error: 0.0\n",
            "w: [-0.2103 -0.6561  2.2408  2.0126], b: -2.8706\n",
            "support vector indices: [53, 55, 64, 67, 69, 71, 73, 77, 78, 79, 84, 85, 107, 111, 117, 120, 124, 126, 127, 128, 130, 132, 134, 135]\n",
            "slack variables: [0.03230731643235485, 0.18870023948449433, 0.00022121446362133312, 0.0, 1.0031114044230325, 0.820812179195265, 1.046871199764618, 0.09494186318882303, 0.8905433684133279, 0.044065763445851225, 1.3534833519572476, 0.049670178487499106, 0.5659567383903044, 0.4141801901290245, 0.1636813269827324, 0.3205648811456774, 0.43304816351474074, 0.00024396925922509638, 0.6775102941802529, 0.8155455368972824, 0.5014369706543547, 0.0, 1.1349760460842235, 0.4398297880282689]\n"
          ]
        }
      ],
      "source": [
        "C_values = [0.25 * t for t in range(1, 5)]  # C = 0.25, 0.5, 0.75, 1.0\n",
        "\n",
        "print(\"\\nQ2.2.3 Calculation using SVM with Slack Variables (C = 0.25 × t, where t = 1,...,4):\")\n",
        "\n",
        "for CC in C_values:\n",
        "    total_train_errors = 0\n",
        "    total_test_errors = 0\n",
        "    class_results = {}\n",
        "\n",
        "    print(\"-------------------------------------------\")\n",
        "    print(f\"C={CC},\")\n",
        "\n",
        "    svm_model = SVC(kernel='linear', C=CC, random_state=0)\n",
        "\n",
        "    #OvR OvA\n",
        "    ovr_classifier = OneVsRestClassifier(svm_model)\n",
        "    ovr_classifier.fit(X_train_scaled, y_train_encoded)\n",
        "    #predict\n",
        "    y_train_pred = ovr_classifier.predict(X_train_scaled)\n",
        "    y_test_pred = ovr_classifier.predict(X_test_scaled)\n",
        "\n",
        "    total_train_errors = np.sum(y_train_pred != y_train_encoded) / len(y_train_encoded)\n",
        "    total_test_errors = np.sum(y_test_pred != y_test_encoded) / len(y_test_encoded)\n",
        "\n",
        "    for idx, cls in enumerate(class_names):\n",
        "        estimator = ovr_classifier.estimators_[idx]\n",
        "\n",
        "        w = estimator.coef_[0].tolist()\n",
        "        b = estimator.intercept_[0]\n",
        "\n",
        "        support_vectors_indices = estimator.support_\n",
        "        support_vectors_instance_ids = [training_id_sorted[i] for i in support_vectors_indices]\n",
        "\n",
        "        y_train_binary = (y_train_encoded == idx).astype(int)\n",
        "        y_train_mapped = y_train_binary * 2 - 1\n",
        "\n",
        "        #decision function values for support vectors\n",
        "        decision_values_sv = estimator.decision_function(X_train_scaled[support_vectors_indices])\n",
        "        y_train_mapped_sv = y_train_mapped[support_vectors_indices]\n",
        "\n",
        "        #slack\n",
        "        slack_vars_sv = np.maximum(0, 1 - y_train_mapped_sv * decision_values_sv).tolist()\n",
        "\n",
        "        #predict\n",
        "        y_train_pred_binary = (y_train_pred == idx).astype(int)\n",
        "        y_test_pred_binary = (y_test_pred == idx).astype(int)\n",
        "\n",
        "        train_error = np.sum(((y_train_pred != y_train_encoded) & (y_train_encoded == idx))/ len(y_train_binary))\n",
        "        test_error = np.sum(((y_test_pred != y_test_encoded) & (y_test_encoded == idx))/ len(y_test_binary))\n",
        "\n",
        "        class_results[cls] = {\n",
        "            'training_error': train_error,\n",
        "            'testing_error': test_error,\n",
        "            'w': w,\n",
        "            'b': b,\n",
        "            'support_vectors': support_vectors_instance_ids,\n",
        "            'slack_variables': slack_vars_sv\n",
        "        }\n",
        "\n",
        "    print(f\"total training error: {total_train_errors}, total testing error: {total_test_errors}\")\n",
        "    for cls in class_names:\n",
        "        res = class_results[cls]\n",
        "        print(f\"\\nclass {cls}:\")\n",
        "        print(f\"training error: {res['training_error']}, testing error: {res['testing_error']}\")\n",
        "        print(f\"w: {np.round(res['w'], 4)}, b: {np.round(res['b'], 4)}\")\n",
        "        print(f\"support vector indices: {res['support_vectors']}\")\n",
        "        print(f\"slack variables: {res['slack_variables']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncVVKOJWijIA"
      },
      "source": [
        "## 2.2.4 Calculation using SVM with Kernel Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqevzWYZiv-k",
        "outputId": "07f5333d-b7fd-46ca-eee6-ab3917f2b28d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2.2.4 Calculation using SVM with Kernel Functions:\n",
            "-------------------------------------------\n",
            "(a) 2nd-order Polynomial Kernel\n",
            "total training error: 0.24761904761904763, total testing error: 0.26666666666666666\n",
            "\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: , b: -2.338\n",
            "support vector indices: [101, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 119, 121, 123, 126, 129, 131, 133, 2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 19, 21, 24, 25, 26, 27, 29, 30, 31, 32, 35]\n",
            "\n",
            "class Iris-versicolor:\n",
            "training error: 0.0, testing error: 0.0\n",
            "w: , b: 1.2868\n",
            "support vector indices: [102, 104, 107, 111, 112, 114, 117, 120, 122, 124, 125, 126, 127, 128, 130, 134, 135, 51, 52, 53, 54, 55, 57, 58, 59, 64, 66, 69, 71, 73, 76, 77, 78, 79, 84]\n",
            "\n",
            "class Iris-virginica:\n",
            "training error: 0.24761904761904766, testing error: 0.24444444444444446\n",
            "w: , b: -1.1291\n",
            "support vector indices: [1, 2, 3, 4, 7, 8, 9, 10, 12, 13, 14, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 51, 52, 53, 54, 57, 58, 60, 61, 66, 71, 78, 81, 82, 85, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135]\n",
            "-------------------------------------------\n",
            "\n",
            "(b) 3rd-order Polynomial Kernel\n",
            "total training error: 0.10476190476190476, total testing error: 0.06666666666666667\n",
            "\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: , b: -0.9896\n",
            "support vector indices: [58, 65, 68, 85, 21, 24, 26, 32]\n",
            "\n",
            "class Iris-versicolor:\n",
            "training error: 0.09523809523809526, testing error: 0.044444444444444446\n",
            "w: , b: -0.9449\n",
            "support vector indices: [4, 7, 9, 12, 14, 21, 24, 25, 26, 27, 28, 29, 32, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 117, 119, 120, 121, 124, 127, 128, 129, 131, 133, 134, 135, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
            "\n",
            "class Iris-virginica:\n",
            "training error: 0.009523809523809525, testing error: 0.0\n",
            "w: , b: -1.0945\n",
            "support vector indices: [51, 52, 53, 54, 55, 57, 59, 60, 64, 66, 69, 71, 73, 76, 77, 78, 79, 84, 102, 104, 107, 111, 112, 114, 116, 117, 120, 122, 124, 125, 126, 127, 128, 130, 134, 135]\n",
            "-------------------------------------------\n",
            "\n",
            "(c) Radial Basis Function Kernel with σ = 1\n",
            "total training error: 0.02857142857142857, total testing error: 0.022222222222222223\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.0\n",
            "w: , b: -0.3511\n",
            "support vector indices: [51, 57, 58, 61, 63, 65, 69, 85, 101, 107, 109, 110, 115, 118, 119, 132, 9, 15, 16, 19, 23, 26, 32, 33]\n",
            "class Iris-versicolor:\n",
            "training error: 0.009523809523809525, testing error: 0.0\n",
            "w: , b: -0.399\n",
            "support vector indices: [9, 16, 19, 23, 24, 26, 33, 102, 104, 107, 109, 111, 117, 119, 120, 122, 124, 126, 127, 128, 130, 132, 134, 135, 51, 53, 54, 55, 57, 58, 60, 61, 63, 69, 71, 73, 77, 78, 79, 84, 85]\n",
            "class Iris-virginica:\n",
            "training error: 0.01904761904761905, testing error: 0.022222222222222223\n",
            "w: , b: -0.2968\n",
            "support vector indices: [9, 14, 15, 16, 19, 21, 23, 33, 51, 53, 54, 55, 57, 60, 61, 64, 69, 71, 73, 77, 78, 79, 84, 85, 101, 102, 107, 109, 110, 111, 114, 117, 119, 120, 122, 124, 126, 127, 128, 130, 132, 134, 135]\n",
            "-------------------------------------------\n",
            "\n",
            "(d) Sigmoidal Kernel with σ = 1\n",
            "total training error: 0.37142857142857144, total testing error: 0.26666666666666666\n",
            "class Iris-setosa:\n",
            "training error: 0.0, testing error: 0.022222222222222223\n",
            "w: , b: -0.583584541469575\n",
            "support vector indices: [58, 61, 65, 80, 81, 82, 132, 2, 4, 9, 13, 14, 26]\n",
            "class Iris-versicolor:\n",
            "training error: 0.20952380952380956, testing error: 0.08888888888888889\n",
            "w: , b: -0.15979735636883713\n",
            "support vector indices: [16, 19, 24, 101, 103, 105, 106, 107, 108, 109, 110, 112, 113, 117, 119, 120, 121, 123, 125, 126, 129, 130, 131, 133, 51, 52, 53, 55, 56, 57, 59, 62, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85]\n",
            "class Iris-virginica:\n",
            "training error: 0.1619047619047619, testing error: 0.15555555555555556\n",
            "w: , b: -3.538003779016435\n",
            "support vector indices: [51, 52, 53, 55, 56, 57, 59, 62, 64, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 101, 103, 105, 106, 107, 108, 109, 110, 112, 113, 118, 119, 120, 121, 123, 125, 126, 129, 130, 131, 132, 133]\n"
          ]
        }
      ],
      "source": [
        "print(\"Q2.2.4 Calculation using SVM with Kernel Functions:\")\n",
        "print(\"-------------------------------------------\")\n",
        "print(\"(a) 2nd-order Polynomial Kernel\")\n",
        "\n",
        "svm_poly2 = SVC(kernel='poly', degree=2, gamma='scale', coef0=0, C=1.0, random_state=0)\n",
        "\n",
        "#OvR OvA\n",
        "ovr_poly2 = OneVsRestClassifier(svm_poly2)\n",
        "ovr_poly2.fit(X_train_scaled, y_train_encoded)\n",
        "#predict\n",
        "y_train_pred = ovr_poly2.predict(X_train_scaled)\n",
        "y_test_pred = ovr_poly2.predict(X_test_scaled)\n",
        "\n",
        "total_train_errors = np.sum(y_train_pred != y_train_encoded) / len(y_train_encoded)\n",
        "total_test_errors = np.sum(y_test_pred != y_test_encoded) / len(y_test_encoded)\n",
        "print(f\"total training error: {total_train_errors}, total testing error: {total_test_errors}\")\n",
        "\n",
        "class_results = {}\n",
        "\n",
        "\n",
        "for idx, cls in enumerate(class_names):\n",
        "    estimator = ovr_poly2.estimators_[idx]\n",
        "\n",
        "    b = estimator.intercept_[0]\n",
        "\n",
        "    support_vectors_indices = estimator.support_\n",
        "    support_vectors_instance_ids = [training_id_sorted[i] for i in support_vectors_indices]\n",
        "\n",
        "    train_error = np.sum(((y_train_pred != y_train_encoded) & (y_train_encoded == idx))/ len(y_train_binary))\n",
        "    test_error = np.sum(((y_test_pred != y_test_encoded) & (y_test_encoded == idx))/ len(y_test_binary))\n",
        "\n",
        "\n",
        "    class_results[cls] = {\n",
        "        'training_error': train_error,\n",
        "        'testing_error': test_error,\n",
        "        'b': b,\n",
        "        'support_vectors': support_vectors_instance_ids\n",
        "    }\n",
        "\n",
        "for cls in class_names:\n",
        "    res = class_results[cls]\n",
        "    print(f\"\\nclass {cls}:\")\n",
        "    print(f\"training error: {res['training_error']}, testing error: {res['testing_error']}\")\n",
        "    print(f\"w: , b: {np.round(res['b'], 4)}\")\n",
        "    print(f\"support vector indices: {res['support_vectors']}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------\")\n",
        "print(\"\\n(b) 3rd-order Polynomial Kernel\")\n",
        "\n",
        "svm_poly3 = SVC(kernel='poly', degree=3, gamma='scale', coef0=0, C=1.0, random_state=0)\n",
        "\n",
        "#OvR OvA\n",
        "ovr_poly3 = OneVsRestClassifier(svm_poly3)\n",
        "ovr_poly3.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "#predict\n",
        "y_train_pred = ovr_poly3.predict(X_train_scaled)\n",
        "y_test_pred = ovr_poly3.predict(X_test_scaled)\n",
        "\n",
        "total_train_errors = np.sum(y_train_pred != y_train_encoded) / len(y_train_encoded)\n",
        "total_test_errors = np.sum(y_test_pred != y_test_encoded) / len(y_test_encoded)\n",
        "print(f\"total training error: {total_train_errors}, total testing error: {total_test_errors}\")\n",
        "\n",
        "class_results = {}\n",
        "\n",
        "for idx, cls in enumerate(class_names):\n",
        "    estimator = ovr_poly3.estimators_[idx]\n",
        "\n",
        "    b = estimator.intercept_[0]\n",
        "\n",
        "    support_vectors_indices = estimator.support_\n",
        "    support_vectors_instance_ids = [training_id_sorted[i] for i in support_vectors_indices]\n",
        "\n",
        "    train_error = np.sum(((y_train_pred != y_train_encoded) & (y_train_encoded == idx))/ len(y_train_binary))\n",
        "    test_error = np.sum(((y_test_pred != y_test_encoded) & (y_test_encoded == idx))/ len(y_test_binary))\n",
        "\n",
        "\n",
        "    class_results[cls] = {\n",
        "        'training_error': train_error,\n",
        "        'testing_error': test_error,\n",
        "        'b': b,\n",
        "        'support_vectors': support_vectors_instance_ids\n",
        "    }\n",
        "\n",
        "for cls in class_names:\n",
        "    res = class_results[cls]\n",
        "    print(f\"\\nclass {cls}:\")\n",
        "    print(f\"training error: {res['training_error']}, testing error: {res['testing_error']}\")\n",
        "    print(f\"w: , b: {np.round(res['b'], 4)}\")\n",
        "    print(f\"support vector indices: {res['support_vectors']}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"------------------1234-------------------------\")\n",
        "print(\"\")\n",
        "print(\"(c) Radial Basis Function Kernel with σ = 1\")\n",
        "\n",
        "# RBF kernel, gamma = 1 / (2 * sigma^2)\n",
        "gamma_value = 1 / (2 * (1 ** 2))  # σ = 1\n",
        "svm_rbf = SVC(kernel='rbf', gamma=gamma_value, C=1.0, random_state=0)\n",
        "\n",
        "#OvR OvA\n",
        "ovr_rbf = OneVsRestClassifier(svm_rbf)\n",
        "ovr_rbf.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "#predict\n",
        "y_train_pred = ovr_rbf.predict(X_train_scaled)\n",
        "y_test_pred = ovr_rbf.predict(X_test_scaled)\n",
        "\n",
        "total_train_errors = np.sum(y_train_pred != y_train_encoded) / len(y_train_encoded)\n",
        "total_test_errors = np.sum(y_test_pred != y_test_encoded) / len(y_test_encoded)\n",
        "print(f\"total training error: {total_train_errors}, total testing error: {total_test_errors}\")\n",
        "\n",
        "class_results = {}\n",
        "\n",
        "for idx, cls in enumerate(class_names):\n",
        "    estimator = ovr_rbf.estimators_[idx]\n",
        "\n",
        "    b = estimator.intercept_[0]\n",
        "\n",
        "    support_vectors_indices = estimator.support_\n",
        "    support_vectors_instance_ids = [training_id_sorted[i] for i in support_vectors_indices]\n",
        "\n",
        "    train_error = np.sum(((y_train_pred != y_train_encoded) & (y_train_encoded == idx))/ len(y_train_binary))\n",
        "    test_error = np.sum(((y_test_pred != y_test_encoded) & (y_test_encoded == idx))/ len(y_test_binary))\n",
        "\n",
        "\n",
        "    class_results[cls] = {\n",
        "        'training_error': train_error,\n",
        "        'testing_error': test_error,\n",
        "        'b': b,\n",
        "        'support_vectors': support_vectors_instance_ids\n",
        "    }\n",
        "\n",
        "for cls in class_names:\n",
        "    res = class_results[cls]\n",
        "    print(f\"class {cls}:\")\n",
        "    print(f\"training error: {res['training_error']}, testing error: {res['testing_error']}\")\n",
        "    print(f\"w: , b: {np.round(res['b'], 4)}\")\n",
        "    print(f\"support vector indices: {res['support_vectors']}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------\")\n",
        "print(\"\")\n",
        "print(\"(d) Sigmoidal Kernel with σ = 1\")\n",
        "\n",
        "# Sigmoid kernel, gamma = 1 / σ\n",
        "svm_sigmoid = SVC(kernel='sigmoid', gamma=1, coef0=0, C=1.0, random_state=0)\n",
        "\n",
        "#OvR OvA\n",
        "ovr_sigmoid = OneVsRestClassifier(svm_sigmoid)\n",
        "ovr_sigmoid.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "#predict\n",
        "y_train_pred = ovr_sigmoid.predict(X_train_scaled)\n",
        "y_test_pred = ovr_sigmoid.predict(X_test_scaled)\n",
        "\n",
        "total_train_errors = np.sum(y_train_pred != y_train_encoded) / len(y_train_encoded)\n",
        "total_test_errors = np.sum(y_test_pred != y_test_encoded) / len(y_test_encoded)\n",
        "print(f\"total training error: {total_train_errors}, total testing error: {total_test_errors}\")\n",
        "\n",
        "class_results = {}\n",
        "\n",
        "for idx, cls in enumerate(class_names):\n",
        "    estimator = ovr_sigmoid.estimators_[idx]\n",
        "\n",
        "    b = estimator.intercept_[0]\n",
        "\n",
        "    support_vectors_indices = estimator.support_\n",
        "    support_vectors_instance_ids = [training_id_sorted[i] for i in support_vectors_indices]\n",
        "\n",
        "    train_error = np.sum(((y_train_pred != y_train_encoded) & (y_train_encoded == idx))/ len(y_train_binary))\n",
        "    test_error = np.sum(((y_test_pred != y_test_encoded) & (y_test_encoded == idx))/ len(y_test_binary))\n",
        "\n",
        "\n",
        "    class_results[cls] = {\n",
        "        'training_error': train_error,\n",
        "        'testing_error': test_error,\n",
        "        'b': b,\n",
        "        'support_vectors': support_vectors_instance_ids\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for cls in class_names:\n",
        "    res = class_results[cls]\n",
        "    print(f\"class {cls}:\")\n",
        "    print(f\"training error: {res['training_error']}, testing error: {res['testing_error']}\")\n",
        "    print(f\"w: , b: {res['b']}\")\n",
        "    print(f\"support vector indices: {res['support_vectors']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
